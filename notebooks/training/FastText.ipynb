{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import fasttext\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "\n",
    "    with open(f'{file}', 'r', encoding='utf-8') as f:\n",
    "        input_lines = f.read().split('\\n')\n",
    "\n",
    "    data = {\n",
    "        \"title\": [],\n",
    "        \"description\": [],\n",
    "        \"recent_posts\": [],\n",
    "    }\n",
    "\n",
    "    for line in input_lines:\n",
    "        try:\n",
    "            line = json.loads(line)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if line != '':\n",
    "            try:\n",
    "                data['title'].append(line['title'])\n",
    "                data['description'].append(line['description'])\n",
    "                data['recent_posts'].append('\\n'.join(line['recent_posts']))\n",
    "            except:\n",
    "                print('Parse error')\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    data['label'] = file.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error\n",
      "Parse error\n",
      "Parse error\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(columns = ['title', 'description', 'recent_posts', 'label'])\n",
    "PATH = Path('tgparser/RU_TGSTAT_DATA/')\n",
    "for file in os.listdir(PATH):\n",
    "    data = pd.concat([data, load_data(str(PATH / file))]).reset_index(drop=True)\n",
    "    \n",
    "data['recent_posts'] = data['recent_posts'].apply(lambda x: x.replace('\\u200b', ''))\n",
    "data['label'] = data['label'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {'Art & Design': '__label__0',\n",
    " 'Bets & Gambling': '__label__1',\n",
    " 'Books': '__label__2',\n",
    " 'Business & Entrepreneurship': '__label__3',\n",
    " 'Cars & Other Vehicles': '__label__4',\n",
    " 'Celebrities & Lifestyle': '__label__5',\n",
    " 'Cryptocurrencies': '__label__6',\n",
    " 'Culture & Events': '__label__7',\n",
    " 'Curious Facts': '__label__8',\n",
    " 'Directories of Channels & Bots': '__label__9',\n",
    " 'Economy & Finance': '__label__10',\n",
    " 'Education': '__label__11',\n",
    " 'Erotic Content': '__label__12',\n",
    " 'Fashion & Beauty': '__label__13',\n",
    " 'Fitness': '__label__14',\n",
    " 'Food & Cooking': '__label__15',\n",
    " 'Foreign Languages': '__label__16',\n",
    " 'Health & Medicine': '__label__17',\n",
    " 'History': '__label__18',\n",
    " 'Hobbies & Activities': '__label__19',\n",
    " 'Home & Architecture': '__label__20',\n",
    " 'Humor & Memes': '__label__21',\n",
    " 'Investments': '__label__22',\n",
    " 'Job Listings': '__label__23',\n",
    " 'Kids & Parenting': '__label__24',\n",
    " 'Marketing & PR': '__label__25',\n",
    " 'Motivation & Self-Development': '__label__26',\n",
    " 'Movies': '__label__27',\n",
    " 'Music': '__label__28',\n",
    " 'Offers & Promotions': '__label__29',\n",
    " 'Pets': '__label__30',\n",
    " 'Politics & Incidents': '__label__31',\n",
    " 'Psychology & Relationships': '__label__32',\n",
    " 'Real Estate': '__label__33',\n",
    " 'Recreation & Entertainment': '__label__34',\n",
    " 'Religion & Spirituality': '__label__35',\n",
    " 'Science': '__label__36',\n",
    " 'Sports': '__label__37',\n",
    " 'Technology & Internet': '__label__38',\n",
    " 'Travel & Tourism': '__label__39',\n",
    " 'Video Games': '__label__40',\n",
    " 'Other': '__label__41'}\n",
    "\n",
    "reverse_mapper = {v: k for k, v in mapper.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove emojis\n",
    "import re\n",
    "\n",
    "\n",
    "def deEmojify(text):    \n",
    "    regex_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"                    \n",
    "                      \"]+\", re.UNICODE)\n",
    "    return regex_pattern.sub(r'',text)\n",
    "\n",
    "data['recent_posts'] = data['recent_posts'].apply(deEmojify)\n",
    "data['title'] = data['title'].apply(deEmojify)\n",
    "data['description'] = data['description'].apply(deEmojify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['recent_posts'] = data['recent_posts'].apply(lambda x: x.lower())\n",
    "data['title'] = data['title'].apply(lambda x: x.lower())\n",
    "data['description'] = data['description'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6732a094f39d4c7183ad3becd2355815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove adds from all posts\n",
    "\n",
    "ALL_POSTS = []\n",
    "for v in tqdm_notebook(data['recent_posts'].apply(lambda x: x.split('\\n'))):\n",
    "    ALL_POSTS.extend(v)\n",
    "post_counts = pd.Series(ALL_POSTS).value_counts().sort_values(ascending = False)\n",
    "\n",
    "\n",
    "def filter_posts(posts, threshold = 5):\n",
    "    posts = posts.split('\\n')\n",
    "    filtered_posts = []\n",
    "    for post in posts:\n",
    "        if post_counts[post] < threshold:\n",
    "            filtered_posts.append(post)\n",
    "    return '\\n'.join(filtered_posts)\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    data.iloc[i, 2] = filter_posts(data.iloc[i, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEmail(text):\n",
    "    pattern = re.compile(\"((\\w+)(\\.|_)?(\\w*)@(\\w+)(\\.(\\w+))+)\")\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "data['recent_posts'] = data['recent_posts'].apply(removeEmail)\n",
    "data['title'] = data['title'].apply(removeEmail)\n",
    "data['description'] = data['description'].apply(removeEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUsername(text):\n",
    "    pattern = re.compile(\"(@(\\w+))\")\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "data['recent_posts'] = data['recent_posts'].apply(removeUsername)\n",
    "data['title'] = data['title'].apply(removeUsername)\n",
    "data['description'] = data['description'].apply(removeUsername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLinks(text):\n",
    "    pattern = re.compile(\"(https?://[^ ]+)\")\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "data['recent_posts'] = data['recent_posts'].apply(removeLinks)\n",
    "data['title'] = data['title'].apply(removeLinks)\n",
    "data['description'] = data['description'].apply(removeLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, shuffle = True, train_size = 0.7)\n",
    "\n",
    "train = train.reset_index(drop = True)\n",
    "test = test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(data):\n",
    "    output_data = []\n",
    "    N_SAMPLES = 10\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(N_SAMPLES):\n",
    "            titleText = data.iloc[i, 0] + data.iloc[i, 1]\n",
    "            posts = '\\n'.join(pd.Series(data.iloc[i, 2].split('\\n')).sample(n = 5, replace = True).values)\n",
    "            output_data.append([mapper[data.iloc[i, 3]], titleText + posts])\n",
    "    return pd.DataFrame(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4949, 4) (2121, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sample_data(train)\n",
    "test = sample_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49490, 2) (21210, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/train.txt', \n",
    "                                          index = False, \n",
    "                                          sep = ' ',\n",
    "                                          header = None, \n",
    "                                          quoting = csv.QUOTE_NONE, \n",
    "                                          quotechar = \"\", \n",
    "                                          escapechar = \" \")\n",
    "\n",
    "\n",
    "test.to_csv('data/test.txt', \n",
    "                                          index = False, \n",
    "                                          sep = ' ',\n",
    "                                          header = None, \n",
    "                                          quoting = csv.QUOTE_NONE, \n",
    "                                          quotechar = \"\", \n",
    "                                          escapechar = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the fastText classifier\n",
    "model = fasttext.train_supervised('data/train.txt', lr=0.5, epoch=10, wordNgrams=1, bucket=200_000, dim=100, loss='ova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21210, 0.48434700612918435, 0.48434700612918435)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating performance on the entire test file\n",
    "model.test('data/test.txt')                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(test.shape[0]):\n",
    "    labels, cur_preds = model.predict(test.iloc[i, 1].replace('\\n', ''), k = -1)\n",
    "    pred_mapper = {}\n",
    "    for i in range(len(labels)):\n",
    "        pred_mapper[labels[i]] = cur_preds[i]\n",
    "        \n",
    "    cur_preds = pd.Series(pred_mapper)[sorted(labels, key=lambda x: int(x.split('__')[-1]))].values \n",
    "    preds.append(list(cur_preds))\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.zeros(preds.shape)\n",
    "\n",
    "target_sorting = np.array(sorted(test[0].unique(), key = lambda x: int(x.split('__')[-1])))\n",
    "for i in range(y_true.shape[0]):\n",
    "    y_true[i, np.argwhere(target_sorting == test[0][i])[0][0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.48217821782178216\n",
      "F1 0.3905931228903149\n",
      "Precision 0.321939586645469\n",
      "Recall 0.49646393210749645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = preds\n",
    "print('Accuracy', accuracy_score(np.argmax(y_true, axis = 1), np.argmax(y_pred, axis = 1)))\n",
    "print('F1', f1_score(y_true, (y_pred == y_pred.max(axis=1, keepdims=1)).astype(float), average='micro'))\n",
    "print('Precision', precision_score(y_true, (y_pred == y_pred.max(axis=1, keepdims=1)).astype(float), average='micro'))\n",
    "print('Recall', recall_score(y_true, (y_pred == y_pred.max(axis=1, keepdims=1)).astype(float), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize the model with retraining\n",
    "model.quantize(input='data/train.txt', qnorm=True, retrain=True, cutoff=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21210, 0.4821310702498821, 0.4821310702498821)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating performance on the entire test file\n",
    "model.test('data/test.txt')                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(test.shape[0]):\n",
    "    labels, cur_preds = model.predict(test.iloc[i, 1].replace('\\n', ''), k = -1)\n",
    "    pred_mapper = {}\n",
    "    for i in range(len(labels)):\n",
    "        pred_mapper[labels[i]] = cur_preds[i]\n",
    "        \n",
    "    cur_preds = pd.Series(pred_mapper)[sorted(labels, key=lambda x: int(x.split('__')[-1]))].values \n",
    "    preds.append(list(cur_preds))\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.zeros(preds.shape)\n",
    "\n",
    "target_sorting = np.array(sorted(test[0].unique(), key = lambda x: int(x.split('__')[-1])))\n",
    "for i in range(y_true.shape[0]):\n",
    "    y_true[i, np.argwhere(target_sorting == test[0][i])[0][0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = preds\n",
    "print('Accuracy', accuracy_score(np.argmax(y_true, axis = 1), np.argmax(y_pred, axis = 1)))\n",
    "print('F1', f1_score(y_true, (y_pred == y_pred.max(axis=1, keepdims=1)).astype(float), average='micro'))\n",
    "print('Precision', precision_score(y_true, (y_pred == y_pred.max(axis=1, keepdims=1)).astype(float), average='micro'))\n",
    "print('Recall', recall_score(y_true, (y_pred == y_pred.max(axis=1, keepdims=1)).astype(float), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = sample_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv('data/train.txt', \n",
    "                                          index = False, \n",
    "                                          sep = ' ',\n",
    "                                          header = None, \n",
    "                                          quoting = csv.QUOTE_NONE, \n",
    "                                          quotechar = \"\", \n",
    "                                          escapechar = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised('data/train.txt', lr=0.5, epoch=10, wordNgrams=1, bucket=200_000, dim=100, loss='ova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.quantize(input='data/train.txt', qnorm=True, retrain=True, cutoff=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized model\n",
    "model.save_model('models/fasttext_42cat_preprocessed.ftz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
